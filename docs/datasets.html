<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>signal_quality.datasets API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>signal_quality.datasets</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import wfdb
import matplotlib.pyplot as plt
import biosppy 
import scipy
import sklearn
from tqdm import tqdm

def load_ecg_by_windows(channel, rates, noise_threshold, window_size=60*125, step=30*125):
    &#34;&#34;&#34;
    channel = the entire raw ECG waveform of shape (length,)
    rates = the processed (numeric) annotations of same shape as ECG (length,)
    sampling_rate = the hz of the input ECG signal
    downsampled_sampling_rate = the hz to downsample to
    window_size = the window, after downsampling, of indices in a feature window
    &#34;&#34;&#34;
    
    # Split into individual heartbeats. For each heartbeat
    # record, append classification (normal/abnormal).
    labels = []
    beats = []

    # Skip first and last beat.
    for idxval in range(window_size, len(channel), step):
        # Get the classification value that is on
        # or near the position of the rpeak index.
        # set as abnormal beat if it exists

        if rates is not None:
            window_labels = rates[max(0,idxval-window_size):idxval]
            
            # Skip beat if there is no classification.
            if (window_labels==-1.0).sum() == len(window_labels):
                continue

            # print((window_labels==1.0).sum() / len(window_labels))
            if ((window_labels==1.0).sum() / len(window_labels)) &gt; noise_threshold:
                catval = 1
            else:
                catval = 0
            labels.append(catval)

        # Append some extra readings around the beat.
        beat = channel[max(0,idxval-window_size):idxval]

        # # Normalize the readings to a 0-1 range for ML purposes.
        # beat_range = beat.max() - beat.min()
        # if beat_range == 0:
        #     continue
        # beat = (beat - beat.min()) / beat_range

        beats.append(beat)

    # return data and labels
    return beats, labels

def load_ecg_beat_by_beat(channel, rates, sampling_rate, beat_window=90, show=False):
    &#34;&#34;&#34;
    channel = the entire raw ECG waveform of shape (length,)
    rates = the processed (numeric) annotations of same shape as ECG (length,)
    sampling_rate = the hz of the input ECG signal
    downsampled_sampling_rate = the hz to downsample to
    beat_window = the window, after downsampling, of indices to get around the peak
    show = a boolean value whether to show the obtained peaks
    &#34;&#34;&#34;
    # Instead of using the annotations to find the beats, we will
    # use R-peak detection instead. The reason for this is so that
    # the same logic can be used to analyze new and un-annotated
    # ECG data. We use the annotations here only to classify the
    # beat as either Normal or Abnormal and to train the model.

    # Find rpeaks in the ECG data. Most should match with
    # the annotations.
    # biosppy.signals.ecg.ecg returns:
    # names = (&#39;ts&#39;, &#39;filtered&#39;, &#39;rpeaks&#39;, &#39;templates_ts&#39;, &#39;templates&#39;,
    #          &#39;heart_rate_ts&#39;, &#39;heart_rate&#39;)
    out = biosppy.signals.ecg.ecg(signal=channel, sampling_rate=sampling_rate, show=show)
    
    # Split into individual heartbeats. For each heartbeat
    # record, append classification (normal/abnormal).
    labels = []
    beats = []

    # Skip first and last beat.
    for idxval in out[&#39;rpeaks&#39;][1:-1]:
        # Get the classification value that is on
        # or near the position of the rpeak index.
        # set as abnormal beat if it exists

        if rates is not None:
            catval = rates[max(0,idxval-beat_window):idxval+beat_window].max()
        
            # Skip beat if there is no classification.
            if catval == -1.0:
                continue            
            labels.append(catval)

        # Append some extra readings around the beat.
        beat = channel[max(0,idxval-beat_window):idxval+beat_window]

        if show:
            plt.plot(beat)
            plt.scatter(beat_window, 1, c=&#39;r&#39;, label=&#39;detected peak&#39;)
            plt.legend(loc=&#39;upper right&#39;); plt.grid(); plt.ylabel(&#39;ECG&#39;); plt.xlabel(str(sampling_rate)+&#39; hz&#39;); plt.show()

        # # Normalize the readings to a 0-1 range for ML purposes.
        # beat_range = beat.max() - beat.min()
        # if beat_range == 0:
        #     continue
        # beat = (beat - beat.min()) / beat_range

        beats.append(beat)

    # return data and labels
    return beats, labels

def get_power(signal):
    &#34;&#34;&#34;&#34; Helper function to return average power of signal
    &#34;&#34;&#34;
    return np.mean(np.power(signal, 2))

def calc_snr(signal, noise):
    &#34;&#34;&#34;&#34; Calculates signal to noise ratio
    &#34;&#34;&#34;
    signal_avg_watts = get_power(signal)
    noise_avg_watts = get_power(noise)
    return 10*(np.log10(signal_avg_watts) - np.log10(noise_avg_watts))


def add_noise(signal, method, target_snr_db=18, random_state=0, verbose=False):
    &#34;&#34;&#34; Adds noise of specified target_snr_db dB to signal

    method = type of noise to add
    &#34;&#34;&#34;

    np.random.seed(random_state)
    # Adding noise using target SNR

    # Calculate signal power and convert to dB 
    sig_avg_watts = get_power(signal)
    sig_avg_db = 10 * np.log10(sig_avg_watts)
    # Calculate noise according to [2] then convert to watts
    noise_avg_db = sig_avg_db - target_snr_db
    noise_avg_watts = 10 ** (noise_avg_db / 10)

    if method == &#39;gaussian&#39;:
        # Generate an sample of white noise
        noise_volts = np.random.normal(0, np.sqrt(noise_avg_watts), len(signal))
    else:
        raise NotImplementedError

    if verbose:
        print(&#39;SNR&#39;, calc_snr(signal, noise_volts))

    # Noise up the original signal
    return signal + noise_volts


def add_noisy_signal(signal, noise, target_snr_db=18, verbose=False):
    &#34;&#34;&#34; Adds noise of specified target_snr_db dB to signal via rescaling
    &#34;&#34;&#34;
    # Calculate signal power and convert to dB 
    sig_avg_watts = get_power(signal)
    sig_avg_db = 10 * np.log10(sig_avg_watts)
    # Calculate noise according to [2] then convert to watts
    noise_avg_db = sig_avg_db - target_snr_db
    noise_avg_watts = 10 ** (noise_avg_db / 10)

    # rescale noise
    noise -= np.mean(noise)
    noise *= np.sqrt(noise_avg_watts) / noise.std()

    if verbose:
        print(&#39;SNR&#39;, calc_snr(signal, noise))

    # Noise up the original signal
    return signal + noise


def load_nstdb_extra(nstdb_path, mitdb_path, verbose=False, downsampled_sampling_rate=125):
    &#34;&#34;&#34; 
    https://physionet.org/content/nstdb/1.0.0/

    ## 1. Install the WFDB package: https://www.physionet.org/content/wfdb/
    ##      Source: Moody, G., Pollard, T., &amp; Moody, B. (2021). WFDB Software Package (version 10.6.2). PhysioNet. https://doi.org/10.13026/zzpx-h016.
    ##      Source: Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... &amp; Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: 
    ##          Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.
    ##
    ## 2. Download the MIT-BIH Noise Stress Test Database: https://physionet.org/content/nstdb/ and rename it to &#34;nstdb&#34;
    ##      Source: Moody GB, Muldrow WE, Mark RG. A noise stress test for arrhythmia detectors. Computers in Cardiology 1984; 11:381-384.
    ##
    ## 3. Download the MIT-BIH: https://physionet.org/content/mitdb/ and rename it to &#34;mitdb&#34;
    ##      Source: Moody GB, Mark RG. The impact of the MIT-BIH Arrhythmia Database. IEEE Eng in Med and Biol 20(3):45-50 (May-June 2001). (PMID: 11446209)
    ##
    ## 4. Run &#34;bash generate_nstdb_extra.sh&#34; to create the nstdb_extra directory
    ##      This takes in 2 clean ECGs (118 and 119) and adds 3 types of noise (baseline wander, muscle EMG artifact, electrode motion artifact)
    ##      at different signal-to-noise ratios (24,18,12,6,0,-6) in dB. Original script only adds one type of noise, this script adds all 3 types.
    ##
    ##      Source: https://physionet.org/content/nstdb/1.0.0/nstdbgen
    ##      Source: https://physionet.org/physiotools/wag/nst-1.htm
    ##

    data_path = path where the .dat, .hea, .atr files are located for every patient
    &#34;&#34;&#34;
    subjects = [&#39;118&#39;, &#39;119&#39;]

    output_dict = {}
    for subject in subjects:
        # Read in the data
        record = wfdb.rdrecord(mitdb_path+subject)
        data = record.p_signal.transpose()

        for noise_type in [&#39;em&#39;, &#39;ma&#39;, &#39;bw&#39;, &#39;gn&#39;]:                    
            for dB in [&#39;_6&#39;,&#39;00&#39;,&#39;06&#39;,&#39;12&#39;,&#39;18&#39;,&#39;24&#39;]:

                int_db = int(dB.replace(&#39;_&#39;,&#39;-&#39;))
                subject_str = subject+noise_type+dB
                output_dict[subject_str] = {}

                # Process each channel separately (2 per input file).
                for channelid, channel in enumerate(data):
                    chname = record.sig_name[channelid]
                    # Resample from 360Hz to 125Hz
                    newsize = int((len(channel) * downsampled_sampling_rate / record.fs) + 0.5)
                    channel = scipy.signal.resample(channel, newsize)

                            
                    if verbose:
                        print(&#39;Name&#39;,subject_str,&#39;ECG channel type:&#39;,chname)
                    
                    if noise_type in [&#39;em&#39;, &#39;ma&#39;, &#39;bw&#39;]:
                        noise_record = wfdb.rdrecord(nstdb_path+noise_type)
                        noise_data = noise_record.p_signal.transpose()
                        noise_channel = noise_data[channelid%2] # alternate channels of noise to add, per literature

                        newsize = int((len(noise_channel) * downsampled_sampling_rate / record.fs) + 0.5)
                        noise_channel = scipy.signal.resample(noise_channel, newsize)

                        output_dict[subject_str][chname] = {&#39;data&#39; : add_noisy_signal(channel, noise_channel, target_snr_db=int_db), &#39;labels&#39; : None}
                    elif noise_type==&#39;gn&#39;:
                        output_dict[subject_str][chname] = {&#39;data&#39; : add_noise(signal=channel, method=&#39;gaussian&#39;, target_snr_db=int_db), &#39;labels&#39; : None}
        
        
        # noise_type==&#39;all&#39;:
        noise_type = &#39;all&#39;
        for dB in [&#39;_6&#39;,&#39;00&#39;,&#39;06&#39;,&#39;12&#39;,&#39;18&#39;,&#39;24&#39;]:

            int_db = int(dB.replace(&#39;_&#39;,&#39;-&#39;))
            subject_str = subject+noise_type+dB
            output_dict[subject_str] = {}

            # Process each channel separately (2 per input file).
            for channelid, channel in enumerate(data):
                chname = record.sig_name[channelid]
                # Resample from 360Hz to 125Hz
                newsize = int((len(channel) * downsampled_sampling_rate / record.fs) + 0.5)
                channel = scipy.signal.resample(channel, newsize)

                all_noise = np.zeros_like(channel)
                for noise_type_ in [&#39;em&#39;, &#39;ma&#39;, &#39;bw&#39;, &#39;gn&#39;]:
                    all_noise += (output_dict[subject+noise_type_+dB][chname][&#39;data&#39;] - channel)
                
                output_dict[subject_str][chname] = {&#39;data&#39; : add_noisy_signal(channel, all_noise, target_snr_db=int_db), &#39;labels&#39; : None}
    
    return output_dict
    


def load_mitdb(data_path, verbose=False, downsampled_sampling_rate=125):
    &#34;&#34;&#34; 
    https://physionet.org/content/mitdb/1.0.0/

    data_path = path where the .dat, .hea, .atr files are located for every patient
    &#34;&#34;&#34;
    
    realbeats = [&#39;L&#39;,&#39;R&#39;,&#39;B&#39;,&#39;A&#39;,&#39;a&#39;,&#39;J&#39;,&#39;S&#39;,&#39;V&#39;,&#39;r&#39;,
                &#39;F&#39;,&#39;e&#39;,&#39;j&#39;,&#39;n&#39;,&#39;E&#39;,&#39;/&#39;,&#39;f&#39;,&#39;Q&#39;,&#39;?&#39;]

    normalbeats = [&#39;N&#39;]

    # Loop through each input file. Each file contains one
    # record of ECG readings, sampled at 360 readings per
    # second.

    # np.warnings.filterwarnings(&#39;error&#39;, category=np.VisibleDeprecationWarning)                  

    subjects = [
        &#39;100&#39;,&#39;101&#39;,&#39;102&#39;,&#39;103&#39;,&#39;104&#39;, &#39;105&#39;,&#39;106&#39;,&#39;107&#39;,&#39;108&#39;,&#39;109&#39;,
        &#39;111&#39;,&#39;112&#39;,&#39;113&#39;,&#39;114&#39;,&#39;115&#39;, &#39;116&#39;,&#39;117&#39;,&#39;118&#39;,&#39;119&#39;,&#39;121&#39;,
        &#39;122&#39;,&#39;123&#39;,&#39;124&#39;,&#39;200&#39;,&#39;201&#39;, &#39;202&#39;,&#39;203&#39;,&#39;205&#39;,&#39;207&#39;,&#39;208&#39;,
        &#39;209&#39;,&#39;210&#39;,&#39;212&#39;,&#39;213&#39;,&#39;214&#39;, &#39;215&#39;,&#39;217&#39;,&#39;219&#39;,&#39;220&#39;,&#39;221&#39;,
        &#39;222&#39;,&#39;223&#39;,&#39;228&#39;,&#39;230&#39;,&#39;231&#39;, &#39;232&#39;,&#39;233&#39;,&#39;234&#39;]

    # subjects = [
    #     &#39;100&#39;,]

    output_dict = {}
    for subject in tqdm(subjects):
        output_dict[subject] = {}

        # Read in the data
        record = wfdb.rdrecord(data_path+subject)
        annotation = wfdb.rdann(data_path+subject, &#39;atr&#39;)

        if verbose:
            # Print some meta informations
            print(&#39;Sampling frequency used for this record:&#39;, record.fs)
            print(&#39;Shape of loaded data array:&#39;, record.p_signal.shape)
            print(&#39;Number of loaded annotations:&#39;, len(annotation.num))
        
        # Get the ECG values from the file.
        data = record.p_signal.transpose()

        # Generate the classifications based on the annotations.
        # -1.0 = undetermined
        # 0.0 = normal
        # 1.0 = abnormal    
        rate = np.zeros_like(annotation.symbol, dtype=&#39;float&#39;)
        rate[~np.isin(annotation.symbol, normalbeats+realbeats)] = -1.0
        rate[np.isin(annotation.symbol, realbeats)] = 1.0
        rate[np.isin(annotation.symbol, normalbeats)] = 0.0

        rates = np.zeros_like(data[0], dtype=&#39;float&#39;)
        rates[annotation.sample] = rate

        
        # Process each channel separately (2 per input file).
        for channelid, channel in enumerate(data):
            chname = record.sig_name[channelid]
            # Resample from 360Hz to 125Hz
            newsize = int((len(channel) * downsampled_sampling_rate / record.fs) + 0.5)
            channel = scipy.signal.resample(channel, newsize)
                 
            if verbose:
                print(&#39;Name&#39;, subject, &#39;ECG channel type:&#39;, chname)
            
            output_dict[subject][chname] = {&#39;data&#39; : channel, &#39;labels&#39; : rates}
    
    return output_dict


def load_picc(data_path, verbose=True):
    &#34;&#34;&#34; 
    https://physionet.org/content/challenge-2011/1.0.0/

    data_path = path where the .dat, .hea, .atr files are located for every patient
    load_method=&#39;beat_by_beat&#39; either load and process data beat by beat, or by &#39;windows&#39;
    
    Note: Different featurizations may be used for each sqi
    &#34;&#34;&#34;
        
    # np.warnings.filterwarnings(&#39;error&#39;, category=np.VisibleDeprecationWarning)                  

    normal_subjects = open(data_path+&#39;set-a/RECORDS-acceptable&#39;, &#39;r&#39;).readlines()
    normal_subjects = [subj.replace(&#39;\n&#39;,&#39;&#39;) for subj in normal_subjects]
    normal_labels = [0.0 for _ in range(len(normal_subjects))]

    abnormal_subjects = open(data_path+&#39;set-a/RECORDS-unacceptable&#39;, &#39;r&#39;).readlines()
    abnormal_subjects = [subj.replace(&#39;\n&#39;,&#39;&#39;) for subj in abnormal_subjects]
    abnormal_labels = [1.0 for _ in range(len(abnormal_subjects))]

    all_subjects = normal_subjects + abnormal_subjects
    all_labels = normal_labels + abnormal_labels

    output_dict = {}
    for subject, label in tqdm(zip(all_subjects, all_labels)):
        output_dict[subject] = {}

        # Read in the data
        record = wfdb.rdrecord(data_path+&#39;set-a/&#39;+subject)

        # Print some meta informations
        if verbose:
            print(&#39;Sampling frequency used for this record:&#39;, record.fs)
            print(&#39;Shape of loaded data array:&#39;, record.p_signal.shape)
        
        # Get the ECG values from the file.
        data = record.p_signal.transpose()
        
        # Process each channel separately (12 per input file).
        for channelid, channel in enumerate(data):
            newsize = int((len(channel) * 125 / record.fs) + 0.5)
            channel = scipy.signal.resample(channel, newsize)

            chname = record.sig_name[channelid]
            if verbose:
                print(&#39;ECG channel type:&#39;, chname)
            output_dict[subject][chname] = {&#39;data&#39;:channel, &#39;label&#39;:label}
    
    return output_dict</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="signal_quality.datasets.add_noise"><code class="name flex">
<span>def <span class="ident">add_noise</span></span>(<span>signal, method, target_snr_db=18, random_state=0, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds noise of specified target_snr_db dB to signal</p>
<p>method = type of noise to add</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_noise(signal, method, target_snr_db=18, random_state=0, verbose=False):
    &#34;&#34;&#34; Adds noise of specified target_snr_db dB to signal

    method = type of noise to add
    &#34;&#34;&#34;

    np.random.seed(random_state)
    # Adding noise using target SNR

    # Calculate signal power and convert to dB 
    sig_avg_watts = get_power(signal)
    sig_avg_db = 10 * np.log10(sig_avg_watts)
    # Calculate noise according to [2] then convert to watts
    noise_avg_db = sig_avg_db - target_snr_db
    noise_avg_watts = 10 ** (noise_avg_db / 10)

    if method == &#39;gaussian&#39;:
        # Generate an sample of white noise
        noise_volts = np.random.normal(0, np.sqrt(noise_avg_watts), len(signal))
    else:
        raise NotImplementedError

    if verbose:
        print(&#39;SNR&#39;, calc_snr(signal, noise_volts))

    # Noise up the original signal
    return signal + noise_volts</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.add_noisy_signal"><code class="name flex">
<span>def <span class="ident">add_noisy_signal</span></span>(<span>signal, noise, target_snr_db=18, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds noise of specified target_snr_db dB to signal via rescaling</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_noisy_signal(signal, noise, target_snr_db=18, verbose=False):
    &#34;&#34;&#34; Adds noise of specified target_snr_db dB to signal via rescaling
    &#34;&#34;&#34;
    # Calculate signal power and convert to dB 
    sig_avg_watts = get_power(signal)
    sig_avg_db = 10 * np.log10(sig_avg_watts)
    # Calculate noise according to [2] then convert to watts
    noise_avg_db = sig_avg_db - target_snr_db
    noise_avg_watts = 10 ** (noise_avg_db / 10)

    # rescale noise
    noise -= np.mean(noise)
    noise *= np.sqrt(noise_avg_watts) / noise.std()

    if verbose:
        print(&#39;SNR&#39;, calc_snr(signal, noise))

    # Noise up the original signal
    return signal + noise</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.calc_snr"><code class="name flex">
<span>def <span class="ident">calc_snr</span></span>(<span>signal, noise)</span>
</code></dt>
<dd>
<div class="desc"><p>" Calculates signal to noise ratio</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_snr(signal, noise):
    &#34;&#34;&#34;&#34; Calculates signal to noise ratio
    &#34;&#34;&#34;
    signal_avg_watts = get_power(signal)
    noise_avg_watts = get_power(noise)
    return 10*(np.log10(signal_avg_watts) - np.log10(noise_avg_watts))</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.get_power"><code class="name flex">
<span>def <span class="ident">get_power</span></span>(<span>signal)</span>
</code></dt>
<dd>
<div class="desc"><p>" Helper function to return average power of signal</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_power(signal):
    &#34;&#34;&#34;&#34; Helper function to return average power of signal
    &#34;&#34;&#34;
    return np.mean(np.power(signal, 2))</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.load_ecg_beat_by_beat"><code class="name flex">
<span>def <span class="ident">load_ecg_beat_by_beat</span></span>(<span>channel, rates, sampling_rate, beat_window=90, show=False)</span>
</code></dt>
<dd>
<div class="desc"><p>channel = the entire raw ECG waveform of shape (length,)
rates = the processed (numeric) annotations of same shape as ECG (length,)
sampling_rate = the hz of the input ECG signal
downsampled_sampling_rate = the hz to downsample to
beat_window = the window, after downsampling, of indices to get around the peak
show = a boolean value whether to show the obtained peaks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ecg_beat_by_beat(channel, rates, sampling_rate, beat_window=90, show=False):
    &#34;&#34;&#34;
    channel = the entire raw ECG waveform of shape (length,)
    rates = the processed (numeric) annotations of same shape as ECG (length,)
    sampling_rate = the hz of the input ECG signal
    downsampled_sampling_rate = the hz to downsample to
    beat_window = the window, after downsampling, of indices to get around the peak
    show = a boolean value whether to show the obtained peaks
    &#34;&#34;&#34;
    # Instead of using the annotations to find the beats, we will
    # use R-peak detection instead. The reason for this is so that
    # the same logic can be used to analyze new and un-annotated
    # ECG data. We use the annotations here only to classify the
    # beat as either Normal or Abnormal and to train the model.

    # Find rpeaks in the ECG data. Most should match with
    # the annotations.
    # biosppy.signals.ecg.ecg returns:
    # names = (&#39;ts&#39;, &#39;filtered&#39;, &#39;rpeaks&#39;, &#39;templates_ts&#39;, &#39;templates&#39;,
    #          &#39;heart_rate_ts&#39;, &#39;heart_rate&#39;)
    out = biosppy.signals.ecg.ecg(signal=channel, sampling_rate=sampling_rate, show=show)
    
    # Split into individual heartbeats. For each heartbeat
    # record, append classification (normal/abnormal).
    labels = []
    beats = []

    # Skip first and last beat.
    for idxval in out[&#39;rpeaks&#39;][1:-1]:
        # Get the classification value that is on
        # or near the position of the rpeak index.
        # set as abnormal beat if it exists

        if rates is not None:
            catval = rates[max(0,idxval-beat_window):idxval+beat_window].max()
        
            # Skip beat if there is no classification.
            if catval == -1.0:
                continue            
            labels.append(catval)

        # Append some extra readings around the beat.
        beat = channel[max(0,idxval-beat_window):idxval+beat_window]

        if show:
            plt.plot(beat)
            plt.scatter(beat_window, 1, c=&#39;r&#39;, label=&#39;detected peak&#39;)
            plt.legend(loc=&#39;upper right&#39;); plt.grid(); plt.ylabel(&#39;ECG&#39;); plt.xlabel(str(sampling_rate)+&#39; hz&#39;); plt.show()

        # # Normalize the readings to a 0-1 range for ML purposes.
        # beat_range = beat.max() - beat.min()
        # if beat_range == 0:
        #     continue
        # beat = (beat - beat.min()) / beat_range

        beats.append(beat)

    # return data and labels
    return beats, labels</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.load_ecg_by_windows"><code class="name flex">
<span>def <span class="ident">load_ecg_by_windows</span></span>(<span>channel, rates, noise_threshold, window_size=7500, step=3750)</span>
</code></dt>
<dd>
<div class="desc"><p>channel = the entire raw ECG waveform of shape (length,)
rates = the processed (numeric) annotations of same shape as ECG (length,)
sampling_rate = the hz of the input ECG signal
downsampled_sampling_rate = the hz to downsample to
window_size = the window, after downsampling, of indices in a feature window</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_ecg_by_windows(channel, rates, noise_threshold, window_size=60*125, step=30*125):
    &#34;&#34;&#34;
    channel = the entire raw ECG waveform of shape (length,)
    rates = the processed (numeric) annotations of same shape as ECG (length,)
    sampling_rate = the hz of the input ECG signal
    downsampled_sampling_rate = the hz to downsample to
    window_size = the window, after downsampling, of indices in a feature window
    &#34;&#34;&#34;
    
    # Split into individual heartbeats. For each heartbeat
    # record, append classification (normal/abnormal).
    labels = []
    beats = []

    # Skip first and last beat.
    for idxval in range(window_size, len(channel), step):
        # Get the classification value that is on
        # or near the position of the rpeak index.
        # set as abnormal beat if it exists

        if rates is not None:
            window_labels = rates[max(0,idxval-window_size):idxval]
            
            # Skip beat if there is no classification.
            if (window_labels==-1.0).sum() == len(window_labels):
                continue

            # print((window_labels==1.0).sum() / len(window_labels))
            if ((window_labels==1.0).sum() / len(window_labels)) &gt; noise_threshold:
                catval = 1
            else:
                catval = 0
            labels.append(catval)

        # Append some extra readings around the beat.
        beat = channel[max(0,idxval-window_size):idxval]

        # # Normalize the readings to a 0-1 range for ML purposes.
        # beat_range = beat.max() - beat.min()
        # if beat_range == 0:
        #     continue
        # beat = (beat - beat.min()) / beat_range

        beats.append(beat)

    # return data and labels
    return beats, labels</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.load_mitdb"><code class="name flex">
<span>def <span class="ident">load_mitdb</span></span>(<span>data_path, verbose=False, downsampled_sampling_rate=125)</span>
</code></dt>
<dd>
<div class="desc"><p><a href="https://physionet.org/content/mitdb/1.0.0/">https://physionet.org/content/mitdb/1.0.0/</a></p>
<p>data_path = path where the .dat, .hea, .atr files are located for every patient</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_mitdb(data_path, verbose=False, downsampled_sampling_rate=125):
    &#34;&#34;&#34; 
    https://physionet.org/content/mitdb/1.0.0/

    data_path = path where the .dat, .hea, .atr files are located for every patient
    &#34;&#34;&#34;
    
    realbeats = [&#39;L&#39;,&#39;R&#39;,&#39;B&#39;,&#39;A&#39;,&#39;a&#39;,&#39;J&#39;,&#39;S&#39;,&#39;V&#39;,&#39;r&#39;,
                &#39;F&#39;,&#39;e&#39;,&#39;j&#39;,&#39;n&#39;,&#39;E&#39;,&#39;/&#39;,&#39;f&#39;,&#39;Q&#39;,&#39;?&#39;]

    normalbeats = [&#39;N&#39;]

    # Loop through each input file. Each file contains one
    # record of ECG readings, sampled at 360 readings per
    # second.

    # np.warnings.filterwarnings(&#39;error&#39;, category=np.VisibleDeprecationWarning)                  

    subjects = [
        &#39;100&#39;,&#39;101&#39;,&#39;102&#39;,&#39;103&#39;,&#39;104&#39;, &#39;105&#39;,&#39;106&#39;,&#39;107&#39;,&#39;108&#39;,&#39;109&#39;,
        &#39;111&#39;,&#39;112&#39;,&#39;113&#39;,&#39;114&#39;,&#39;115&#39;, &#39;116&#39;,&#39;117&#39;,&#39;118&#39;,&#39;119&#39;,&#39;121&#39;,
        &#39;122&#39;,&#39;123&#39;,&#39;124&#39;,&#39;200&#39;,&#39;201&#39;, &#39;202&#39;,&#39;203&#39;,&#39;205&#39;,&#39;207&#39;,&#39;208&#39;,
        &#39;209&#39;,&#39;210&#39;,&#39;212&#39;,&#39;213&#39;,&#39;214&#39;, &#39;215&#39;,&#39;217&#39;,&#39;219&#39;,&#39;220&#39;,&#39;221&#39;,
        &#39;222&#39;,&#39;223&#39;,&#39;228&#39;,&#39;230&#39;,&#39;231&#39;, &#39;232&#39;,&#39;233&#39;,&#39;234&#39;]

    # subjects = [
    #     &#39;100&#39;,]

    output_dict = {}
    for subject in tqdm(subjects):
        output_dict[subject] = {}

        # Read in the data
        record = wfdb.rdrecord(data_path+subject)
        annotation = wfdb.rdann(data_path+subject, &#39;atr&#39;)

        if verbose:
            # Print some meta informations
            print(&#39;Sampling frequency used for this record:&#39;, record.fs)
            print(&#39;Shape of loaded data array:&#39;, record.p_signal.shape)
            print(&#39;Number of loaded annotations:&#39;, len(annotation.num))
        
        # Get the ECG values from the file.
        data = record.p_signal.transpose()

        # Generate the classifications based on the annotations.
        # -1.0 = undetermined
        # 0.0 = normal
        # 1.0 = abnormal    
        rate = np.zeros_like(annotation.symbol, dtype=&#39;float&#39;)
        rate[~np.isin(annotation.symbol, normalbeats+realbeats)] = -1.0
        rate[np.isin(annotation.symbol, realbeats)] = 1.0
        rate[np.isin(annotation.symbol, normalbeats)] = 0.0

        rates = np.zeros_like(data[0], dtype=&#39;float&#39;)
        rates[annotation.sample] = rate

        
        # Process each channel separately (2 per input file).
        for channelid, channel in enumerate(data):
            chname = record.sig_name[channelid]
            # Resample from 360Hz to 125Hz
            newsize = int((len(channel) * downsampled_sampling_rate / record.fs) + 0.5)
            channel = scipy.signal.resample(channel, newsize)
                 
            if verbose:
                print(&#39;Name&#39;, subject, &#39;ECG channel type:&#39;, chname)
            
            output_dict[subject][chname] = {&#39;data&#39; : channel, &#39;labels&#39; : rates}
    
    return output_dict</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.load_nstdb_extra"><code class="name flex">
<span>def <span class="ident">load_nstdb_extra</span></span>(<span>nstdb_path, mitdb_path, verbose=False, downsampled_sampling_rate=125)</span>
</code></dt>
<dd>
<div class="desc"><p><a href="https://physionet.org/content/nstdb/1.0.0/">https://physionet.org/content/nstdb/1.0.0/</a></p>
<h2 id="1-install-the-wfdb-package-httpswwwphysionetorgcontentwfdb">1. Install the WFDB package: <a href="https://www.physionet.org/content/wfdb/">https://www.physionet.org/content/wfdb/</a></h2>
<h2 id="source-moody-g-pollard-t-moody-b-2021-wfdb-software-package-version-1062-physionet-httpsdoiorg1013026zzpx-h016">Source: Moody, G., Pollard, T., &amp; Moody, B. (2021). WFDB Software Package (version 10.6.2). PhysioNet. <a href="https://doi.org/10.13026/zzpx-h016.">https://doi.org/10.13026/zzpx-h016.</a></h2>
<h2 id="source-goldberger-a-amaral-l-glass-l-hausdorff-j-ivanov-p-c-mark-r-stanley-h-e-2000-physiobank-physiotoolkit-and-physionet">Source: Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., &hellip; &amp; Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet:</h2>
<h2 id="components-of-a-new-research-resource-for-complex-physiologic-signals-circulation-online-101-23-pp-e215e220">Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.</h2>
<h2 id="_1"></h2>
<h2 id="2-download-the-mit-bih-noise-stress-test-database-httpsphysionetorgcontentnstdb-and-rename-it-to-nstdb">2. Download the MIT-BIH Noise Stress Test Database: <a href="https://physionet.org/content/nstdb/">https://physionet.org/content/nstdb/</a> and rename it to "nstdb"</h2>
<h2 id="source-moody-gb-muldrow-we-mark-rg-a-noise-stress-test-for-arrhythmia-detectors-computers-in-cardiology-1984-11381-384">Source: Moody GB, Muldrow WE, Mark RG. A noise stress test for arrhythmia detectors. Computers in Cardiology 1984; 11:381-384.</h2>
<h2 id="_2"></h2>
<h2 id="3-download-the-mit-bih-httpsphysionetorgcontentmitdb-and-rename-it-to-mitdb">3. Download the MIT-BIH: <a href="https://physionet.org/content/mitdb/">https://physionet.org/content/mitdb/</a> and rename it to "mitdb"</h2>
<h2 id="source-moody-gb-mark-rg-the-impact-of-the-mit-bih-arrhythmia-database-ieee-eng-in-med-and-biol-20345-50-may-june-2001-pmid-11446209">Source: Moody GB, Mark RG. The impact of the MIT-BIH Arrhythmia Database. IEEE Eng in Med and Biol 20(3):45-50 (May-June 2001). (PMID: 11446209)</h2>
<h2 id="_3"></h2>
<h2 id="4-run-bash-generate_nstdb_extrash-to-create-the-nstdb_extra-directory">4. Run "bash generate_nstdb_extra.sh" to create the nstdb_extra directory</h2>
<h2 id="this-takes-in-2-clean-ecgs-118-and-119-and-adds-3-types-of-noise-baseline-wander-muscle-emg-artifact-electrode-motion-artifact">This takes in 2 clean ECGs (118 and 119) and adds 3 types of noise (baseline wander, muscle EMG artifact, electrode motion artifact)</h2>
<h2 id="at-different-signal-to-noise-ratios-24181260-6-in-db-original-script-only-adds-one-type-of-noise-this-script-adds-all-3-types">at different signal-to-noise ratios (24,18,12,6,0,-6) in dB. Original script only adds one type of noise, this script adds all 3 types.</h2>
<h2 id="_4"></h2>
<h2 id="source-httpsphysionetorgcontentnstdb100nstdbgen">Source: <a href="https://physionet.org/content/nstdb/1.0.0/nstdbgen">https://physionet.org/content/nstdb/1.0.0/nstdbgen</a></h2>
<h2 id="source-httpsphysionetorgphysiotoolswagnst-1htm">Source: <a href="https://physionet.org/physiotools/wag/nst-1.htm">https://physionet.org/physiotools/wag/nst-1.htm</a></h2>
<h2 id="_5"></h2>
<p>data_path = path where the .dat, .hea, .atr files are located for every patient</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_nstdb_extra(nstdb_path, mitdb_path, verbose=False, downsampled_sampling_rate=125):
    &#34;&#34;&#34; 
    https://physionet.org/content/nstdb/1.0.0/

    ## 1. Install the WFDB package: https://www.physionet.org/content/wfdb/
    ##      Source: Moody, G., Pollard, T., &amp; Moody, B. (2021). WFDB Software Package (version 10.6.2). PhysioNet. https://doi.org/10.13026/zzpx-h016.
    ##      Source: Goldberger, A., Amaral, L., Glass, L., Hausdorff, J., Ivanov, P. C., Mark, R., ... &amp; Stanley, H. E. (2000). PhysioBank, PhysioToolkit, and PhysioNet: 
    ##          Components of a new research resource for complex physiologic signals. Circulation [Online]. 101 (23), pp. e215–e220.
    ##
    ## 2. Download the MIT-BIH Noise Stress Test Database: https://physionet.org/content/nstdb/ and rename it to &#34;nstdb&#34;
    ##      Source: Moody GB, Muldrow WE, Mark RG. A noise stress test for arrhythmia detectors. Computers in Cardiology 1984; 11:381-384.
    ##
    ## 3. Download the MIT-BIH: https://physionet.org/content/mitdb/ and rename it to &#34;mitdb&#34;
    ##      Source: Moody GB, Mark RG. The impact of the MIT-BIH Arrhythmia Database. IEEE Eng in Med and Biol 20(3):45-50 (May-June 2001). (PMID: 11446209)
    ##
    ## 4. Run &#34;bash generate_nstdb_extra.sh&#34; to create the nstdb_extra directory
    ##      This takes in 2 clean ECGs (118 and 119) and adds 3 types of noise (baseline wander, muscle EMG artifact, electrode motion artifact)
    ##      at different signal-to-noise ratios (24,18,12,6,0,-6) in dB. Original script only adds one type of noise, this script adds all 3 types.
    ##
    ##      Source: https://physionet.org/content/nstdb/1.0.0/nstdbgen
    ##      Source: https://physionet.org/physiotools/wag/nst-1.htm
    ##

    data_path = path where the .dat, .hea, .atr files are located for every patient
    &#34;&#34;&#34;
    subjects = [&#39;118&#39;, &#39;119&#39;]

    output_dict = {}
    for subject in subjects:
        # Read in the data
        record = wfdb.rdrecord(mitdb_path+subject)
        data = record.p_signal.transpose()

        for noise_type in [&#39;em&#39;, &#39;ma&#39;, &#39;bw&#39;, &#39;gn&#39;]:                    
            for dB in [&#39;_6&#39;,&#39;00&#39;,&#39;06&#39;,&#39;12&#39;,&#39;18&#39;,&#39;24&#39;]:

                int_db = int(dB.replace(&#39;_&#39;,&#39;-&#39;))
                subject_str = subject+noise_type+dB
                output_dict[subject_str] = {}

                # Process each channel separately (2 per input file).
                for channelid, channel in enumerate(data):
                    chname = record.sig_name[channelid]
                    # Resample from 360Hz to 125Hz
                    newsize = int((len(channel) * downsampled_sampling_rate / record.fs) + 0.5)
                    channel = scipy.signal.resample(channel, newsize)

                            
                    if verbose:
                        print(&#39;Name&#39;,subject_str,&#39;ECG channel type:&#39;,chname)
                    
                    if noise_type in [&#39;em&#39;, &#39;ma&#39;, &#39;bw&#39;]:
                        noise_record = wfdb.rdrecord(nstdb_path+noise_type)
                        noise_data = noise_record.p_signal.transpose()
                        noise_channel = noise_data[channelid%2] # alternate channels of noise to add, per literature

                        newsize = int((len(noise_channel) * downsampled_sampling_rate / record.fs) + 0.5)
                        noise_channel = scipy.signal.resample(noise_channel, newsize)

                        output_dict[subject_str][chname] = {&#39;data&#39; : add_noisy_signal(channel, noise_channel, target_snr_db=int_db), &#39;labels&#39; : None}
                    elif noise_type==&#39;gn&#39;:
                        output_dict[subject_str][chname] = {&#39;data&#39; : add_noise(signal=channel, method=&#39;gaussian&#39;, target_snr_db=int_db), &#39;labels&#39; : None}
        
        
        # noise_type==&#39;all&#39;:
        noise_type = &#39;all&#39;
        for dB in [&#39;_6&#39;,&#39;00&#39;,&#39;06&#39;,&#39;12&#39;,&#39;18&#39;,&#39;24&#39;]:

            int_db = int(dB.replace(&#39;_&#39;,&#39;-&#39;))
            subject_str = subject+noise_type+dB
            output_dict[subject_str] = {}

            # Process each channel separately (2 per input file).
            for channelid, channel in enumerate(data):
                chname = record.sig_name[channelid]
                # Resample from 360Hz to 125Hz
                newsize = int((len(channel) * downsampled_sampling_rate / record.fs) + 0.5)
                channel = scipy.signal.resample(channel, newsize)

                all_noise = np.zeros_like(channel)
                for noise_type_ in [&#39;em&#39;, &#39;ma&#39;, &#39;bw&#39;, &#39;gn&#39;]:
                    all_noise += (output_dict[subject+noise_type_+dB][chname][&#39;data&#39;] - channel)
                
                output_dict[subject_str][chname] = {&#39;data&#39; : add_noisy_signal(channel, all_noise, target_snr_db=int_db), &#39;labels&#39; : None}
    
    return output_dict</code></pre>
</details>
</dd>
<dt id="signal_quality.datasets.load_picc"><code class="name flex">
<span>def <span class="ident">load_picc</span></span>(<span>data_path, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p><a href="https://physionet.org/content/challenge-2011/1.0.0/">https://physionet.org/content/challenge-2011/1.0.0/</a></p>
<p>data_path = path where the .dat, .hea, .atr files are located for every patient
load_method='beat_by_beat' either load and process data beat by beat, or by 'windows'</p>
<p>Note: Different featurizations may be used for each sqi</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_picc(data_path, verbose=True):
    &#34;&#34;&#34; 
    https://physionet.org/content/challenge-2011/1.0.0/

    data_path = path where the .dat, .hea, .atr files are located for every patient
    load_method=&#39;beat_by_beat&#39; either load and process data beat by beat, or by &#39;windows&#39;
    
    Note: Different featurizations may be used for each sqi
    &#34;&#34;&#34;
        
    # np.warnings.filterwarnings(&#39;error&#39;, category=np.VisibleDeprecationWarning)                  

    normal_subjects = open(data_path+&#39;set-a/RECORDS-acceptable&#39;, &#39;r&#39;).readlines()
    normal_subjects = [subj.replace(&#39;\n&#39;,&#39;&#39;) for subj in normal_subjects]
    normal_labels = [0.0 for _ in range(len(normal_subjects))]

    abnormal_subjects = open(data_path+&#39;set-a/RECORDS-unacceptable&#39;, &#39;r&#39;).readlines()
    abnormal_subjects = [subj.replace(&#39;\n&#39;,&#39;&#39;) for subj in abnormal_subjects]
    abnormal_labels = [1.0 for _ in range(len(abnormal_subjects))]

    all_subjects = normal_subjects + abnormal_subjects
    all_labels = normal_labels + abnormal_labels

    output_dict = {}
    for subject, label in tqdm(zip(all_subjects, all_labels)):
        output_dict[subject] = {}

        # Read in the data
        record = wfdb.rdrecord(data_path+&#39;set-a/&#39;+subject)

        # Print some meta informations
        if verbose:
            print(&#39;Sampling frequency used for this record:&#39;, record.fs)
            print(&#39;Shape of loaded data array:&#39;, record.p_signal.shape)
        
        # Get the ECG values from the file.
        data = record.p_signal.transpose()
        
        # Process each channel separately (12 per input file).
        for channelid, channel in enumerate(data):
            newsize = int((len(channel) * 125 / record.fs) + 0.5)
            channel = scipy.signal.resample(channel, newsize)

            chname = record.sig_name[channelid]
            if verbose:
                print(&#39;ECG channel type:&#39;, chname)
            output_dict[subject][chname] = {&#39;data&#39;:channel, &#39;label&#39;:label}
    
    return output_dict</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="signal_quality" href="index.html">signal_quality</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="signal_quality.datasets.add_noise" href="#signal_quality.datasets.add_noise">add_noise</a></code></li>
<li><code><a title="signal_quality.datasets.add_noisy_signal" href="#signal_quality.datasets.add_noisy_signal">add_noisy_signal</a></code></li>
<li><code><a title="signal_quality.datasets.calc_snr" href="#signal_quality.datasets.calc_snr">calc_snr</a></code></li>
<li><code><a title="signal_quality.datasets.get_power" href="#signal_quality.datasets.get_power">get_power</a></code></li>
<li><code><a title="signal_quality.datasets.load_ecg_beat_by_beat" href="#signal_quality.datasets.load_ecg_beat_by_beat">load_ecg_beat_by_beat</a></code></li>
<li><code><a title="signal_quality.datasets.load_ecg_by_windows" href="#signal_quality.datasets.load_ecg_by_windows">load_ecg_by_windows</a></code></li>
<li><code><a title="signal_quality.datasets.load_mitdb" href="#signal_quality.datasets.load_mitdb">load_mitdb</a></code></li>
<li><code><a title="signal_quality.datasets.load_nstdb_extra" href="#signal_quality.datasets.load_nstdb_extra">load_nstdb_extra</a></code></li>
<li><code><a title="signal_quality.datasets.load_picc" href="#signal_quality.datasets.load_picc">load_picc</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>