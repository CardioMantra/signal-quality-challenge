{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T01:34:23.524280Z",
     "start_time": "2024-12-20T01:34:20.285915Z"
    }
   },
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "from tqdm.notebook import tqdm\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import sys\n",
    "import sklearn\n",
    "import datasets, sqis, featurization, helpers"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T01:36:15.307987Z",
     "start_time": "2024-12-20T01:34:23.527466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path='./data/PICC/'\n",
    "output_dict = datasets.load_picc(data_path=data_path, verbose=False)\n",
    "\n",
    "X_features_dict = {'features': [], 'y_list': [], 'subject': []}\n",
    "\n",
    "X_features_dict = helpers.generate_features_dict_outlier(output_dict, X_features_dict)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "998it [00:02, 437.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/998 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daeb97c300bc46c2944498e8573c8aa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-20T01:36:15.356572Z"
    }
   },
   "source": [
    "## Note that exact results cannot be reproduced as the official PICC challenge is trained on the entirety of set-a and evaluated on set-b\n",
    "import sklearn.ensemble\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.auto_encoder import AutoEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys, os\n",
    "\n",
    "subjects = np.array(X_features_dict['subject'])\n",
    "gkf = sklearn.model_selection.GroupKFold(n_splits=5)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "print('Method, Train AUC, Train Accuracy, Test AUC, Test Accuracy')\n",
    "# for method in ['KNN', \"IForest\", \"PCA\", \"OCSVM\", \"AutoEncoder\"]:\n",
    "for method in ['KNN', \"IForest\", \"OCSVM\", \"AutoEncoder\"]:\n",
    "    print(method)\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    test_accs = []\n",
    "    test_tprs = []\n",
    "    test_aucs = []\n",
    "    train_accs = []\n",
    "    train_aucs = []\n",
    "\n",
    "    for train_split, test_split in gkf.split(subjects, groups=subjects):\n",
    "        # print(\"%s %s\" % (subjects[train_split], subjects[test_split]))\n",
    "        X_train_features_cleaned = np.nan_to_num(np.array(X_features_dict['features'])[train_split], nan=0.0, posinf=10000, neginf=-10000)\n",
    "        X_test_features_cleaned = np.nan_to_num(np.array(X_features_dict['features'])[test_split], nan=0.0, posinf=10000, neginf=-10000)\n",
    "        y_train = np.array(X_features_dict['y_list'])[train_split]\n",
    "        y_test = np.array(X_features_dict['y_list'])[test_split]\n",
    "    \n",
    "        # model = sklearn.ensemble.RandomForestClassifier(random_state=0, n_estimators=1000, max_depth=5, n_jobs=10)\n",
    "        # model.fit(X_train_features_cleaned, y_train)\n",
    "        # scores = model.predict_proba(X_test_features_cleaned)[:,1]\n",
    "        contamination = np.sum(y_train==1)/len(y_train)\n",
    "        print(contamination)\n",
    "\n",
    "        if method == 'IForest':\n",
    "            model = IForest(n_estimators=1000, max_samples=\"auto\", contamination=contamination, max_features=1.0, \n",
    "                bootstrap=False, n_jobs=10, behaviour='new', random_state=0)            \n",
    "        elif method == 'KNN':\n",
    "            model = KNN(contamination=contamination, n_neighbors=5, method='median', radius=1.0, algorithm='auto', \n",
    "                leaf_size=30, metric='l1', p=2, metric_params=None, n_jobs=1)\n",
    "        elif method == 'PCA':\n",
    "            model = PCA(n_components=None, n_selected_components=None, contamination=contamination, copy=True, \n",
    "                whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None, \n",
    "                weighted=True, standardization=True)\n",
    "        elif method == 'OCSVM':\n",
    "            model =  OCSVM(kernel='rbf', degree=3, gamma='auto', coef0=0.0, tol=0.001, nu=0.5, shrinking=True, \n",
    "                cache_size=200, verbose=False, max_iter=- 1, contamination=contamination)\n",
    "        elif method == 'AutoEncoder':\n",
    "            torch.manual_seed(0)\n",
    "            np.random.seed(0)\n",
    "            model = AutoEncoder(hidden_neurons=[32, 32], hidden_activation='relu', batch_norm=True, \n",
    "                learning_rate=0.001, epochs=100, batch_size=32, dropout_rate=0.2, weight_decay=1e-05, \n",
    "                preprocessing=True, loss_fn=None, contamination=contamination, device=None)\n",
    "        \n",
    "        sys.stdout = open(os.devnull, 'w') # Block print from autoencoder fitting\n",
    "        model.fit(X_train_features_cleaned)\n",
    "        sys.stdout = sys.__stdout__ # reenable print\n",
    "\n",
    "        test_scores = model.decision_function(X_test_features_cleaned)\n",
    "        train_scores = model.decision_function(X_train_features_cleaned)\n",
    "\n",
    "        train_accs.append(sklearn.metrics.accuracy_score(y_true=y_train, y_pred=train_scores > model.threshold_))\n",
    "        train_aucs.append(sklearn.metrics.roc_auc_score(y_true=y_train, y_score=train_scores))\n",
    "        test_accs.append(sklearn.metrics.accuracy_score(y_true=y_test, y_pred=test_scores > model.threshold_))\n",
    "        test_aucs.append(sklearn.metrics.roc_auc_score(y_true=y_test, y_score=test_scores))\n",
    "\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, test_scores, pos_label=1)\n",
    "        test_tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        \n",
    "\n",
    "    mean_tpr = np.mean(test_tprs, axis=0)\n",
    "    std_tpr = np.std(test_tprs, axis=0)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=method)\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.grid(); plt.legend(loc=\"lower right\")\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color=\"navy\", linestyle=\"--\")\n",
    "    plt.xscale('log'); \n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=method)\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.grid(); plt.legend(loc=\"lower right\")\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color=\"navy\", linestyle=\"--\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(1-mean_tpr, 1-mean_fpr, label=method)\n",
    "    plt.xlabel('FNR'); plt.ylabel('TNR'); plt.grid(); plt.legend(loc=\"upper left\")\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color=\"navy\", linestyle=\"--\")\n",
    "    plt.xscale('log')\n",
    "    \n",
    "#     plt.plot(mean_fpr, mean_tpr, label=method)\n",
    "    # plt.fill_between(mean_fpr, mean_tpr-std_tpr, mean_tpr+std_tpr, alpha=.2)\n",
    "    print(\"{}, {:0.3f} $\\pm$ {:0.3f}, {:0.3f} $\\pm$ {:0.3f} , {:0.3f} $\\pm$ {:0.3f}, {:0.3f} $\\pm$ {:0.3f}\".format(\\\n",
    "        method, np.mean(test_aucs), np.std(test_aucs), np.mean(test_accs), np.std(test_accs), \\\n",
    "        np.mean(train_aucs), np.std(train_aucs), np.mean(train_accs), np.std(train_accs)))\n",
    "plt.subplot(1, 3, 1); plt.grid();\n",
    "plt.subplot(1, 3, 2); plt.grid();\n",
    "plt.subplot(1, 3, 3); plt.grid();\n",
    "plt.show()\n",
    "# plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.0]); \n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(\"Test ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\"); plt.grid()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method, Train AUC, Train Accuracy, Test AUC, Test Accuracy\n",
      "KNN\n",
      "0.22556390977443608\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sklearn\n",
    "\n",
    "fprs, tprs, thresholds = sklearn.metrics.roc_curve(y_test, test_scores, pos_label=1)\n",
    "fnrs = 1-tprs\n",
    "tnrs = 1-fprs\n",
    "\n",
    "def get_rates(y_test, test_scores, thresholds):\n",
    "    fprs_ = []\n",
    "    tprs_ = []\n",
    "    fnrs_ = []\n",
    "    tnrs_ = []\n",
    "    \n",
    "    for thresh in thresholds:\n",
    "        confusion_matrix = sklearn.metrics.confusion_matrix(y_test, test_scores>=thresh)\n",
    "        print(confusion_matrix.shape)\n",
    "        FP = confusion_matrix[0,1]  \n",
    "        FN = confusion_matrix[1,0]\n",
    "        TP = confusion_matrix[1,1]\n",
    "        TN = confusion_matrix[0,0]\n",
    "        # Sensitivity, hit rate, recall, or true positive rate\n",
    "        tprs_.append(TP/(TP+FN))\n",
    "        # Specificity or true negative rate\n",
    "        tnrs_.append(TN/(TN+FP))  \n",
    "        # Fall out or false positive rate\n",
    "        fprs_.append(FP/(FP+TN))\n",
    "        # False negative rate\n",
    "        fnrs_.append(FN/(TP+FN))\n",
    "        \n",
    "    return np.array(fprs_), np.array(tprs_), np.array(fnrs_), np.array(tnrs_)\n",
    "    \n",
    "fprs2, tprs2, fnrs2, tnrs2 = get_rates(y_test, test_scores, thresholds)\n",
    "\n",
    "print(fprs==fprs2)\n",
    "print(tprs==tprs2)\n",
    "print(fnrs==fnrs2)\n",
    "print(tnrs==tnrs2)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03fdc303e447c85257badfce409906c7c1c4ada5d52025cf8661518429577854"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
