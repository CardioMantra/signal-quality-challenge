{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 116] Stale file handle: '/zfsauton/project/public/chufang/PICC/set-a/2511400.hea'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_261027/97632381.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/zfsauton/project/public/chufang/PICC/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mdatfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'set-a/2511400'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/miladi/lib/python3.9/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdrecord\u001b[0;34m(record_name, sampfrom, sampto, channels, physical, pn_dir, m2s, smooth_frames, ignore_skew, return_res, force_channels, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   3431\u001b[0m         \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav2mit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpn_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpn_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3433\u001b[0;31m         \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpn_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpn_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3435\u001b[0m     \u001b[0;31m# Set defaults for sampto and channels input variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/miladi/lib/python3.9/site-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdheader\u001b[0;34m(record_name, pn_dir, rd_segments)\u001b[0m\n\u001b[1;32m   3257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3258\u001b[0m     \u001b[0;31m# Read the header file. Separate comment and non-comment lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3259\u001b[0;31m     header_lines, comment_lines = _header._read_header_lines(base_record_name,\n\u001b[0m\u001b[1;32m   3260\u001b[0m                                                              dir_name, pn_dir)\n\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/miladi/lib/python3.9/site-packages/wfdb/io/_header.py\u001b[0m in \u001b[0;36m_read_header_lines\u001b[0;34m(base_record_name, dir_name, pn_dir)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;31m# Read local file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpn_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m             \u001b[0;31m# Record line followed by signal/segment lines if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0mheader_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 116] Stale file handle: '/zfsauton/project/public/chufang/PICC/set-a/2511400.hea'"
     ]
    }
   ],
   "source": [
    "# This code has been adapted from https://github.com/koen-aerts/ECG_ML\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_signal(datfile, SAMPLE_START, SAMPLE_SIZE, CHANNEL, extract_annotation=False):\n",
    "    record = wfdb.rdrecord(datfile)\n",
    "    \n",
    "    # Get data and annotations for the samples selected below.\n",
    "    SAMPLE_END = SAMPLE_START + SAMPLE_SIZE\n",
    "    channel = record.p_signal[SAMPLE_START:SAMPLE_END, CHANNEL]\n",
    "\n",
    "    # Plot the heart beats. Time scale is number of readings divided by sampling frequency.\n",
    "    times = (np.arange(SAMPLE_START, SAMPLE_END, dtype='float')) / record.fs\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(times, channel)\n",
    "\n",
    "    if extract_annotation:\n",
    "        # Extract annotations.\n",
    "        annotation = wfdb.rdann(datfile, 'atr')\n",
    "        \n",
    "        where = np.logical_and(annotation.sample >= SAMPLE_START, annotation.sample < SAMPLE_END)\n",
    "        annotation_symbol = np.array(annotation.symbol)[where]\n",
    "        annotimes = annotation.sample[where] / record.fs\n",
    "\n",
    "        # Plot the Annotations \n",
    "        plt.scatter(annotimes, np.ones_like(annotimes) * channel.max() * 1.4, c='r')\n",
    "        for idx in range(len(annotimes)):\n",
    "            plt.annotate(annotation_symbol[idx], xy = (annotimes[idx], channel.max() * 1.3))\n",
    "\n",
    "    plt.xlim([SAMPLE_START / record.fs, (SAMPLE_END / record.fs) + 1])\n",
    "    plt.xlabel('Offset (Seconds from start)')\n",
    "    plt.ylabel(record.sig_name[CHANNEL])\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# PICC data directory path\n",
    "# Read in example signal\n",
    "data_path='/zfsauton/project/public/chufang/PICC/'\n",
    "datfile = data_path+'set-a/2511400'\n",
    "record = wfdb.rdrecord(datfile)\n",
    "print(record.__dict__)\n",
    "\n",
    "## Read in annotations\n",
    "## Mote that there are no annotations for PICC data, but there are for MIT-BIH\n",
    "# annotation = wfdb.rdann(data_path+'100', extension='atr')\n",
    "# annotation.__dict__\n",
    "\n",
    "SAMPLE_START=0   # Start of the sample in the file.\n",
    "SAMPLE_SIZE=500*10      # Number of readings (500 per second).\n",
    "CHANNEL=0             # There are 2 channels\n",
    "plot_signal(datfile, SAMPLE_START, SAMPLE_SIZE, CHANNEL, extract_annotation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "from tqdm.notebook import tqdm\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import sys\n",
    "import sklearn\n",
    "sys.path.append('../')\n",
    "import datasets, sqis, featurization\n",
    "\n",
    "\n",
    "def get_features(subject_dict, sampling_rate=125, window_size=10):\n",
    "    X_features_dict = {\n",
    "        'zhao2018': [],\n",
    "        'orphanidou2015': [],\n",
    "        'li2007': [],\n",
    "        'clifford2012': [],\n",
    "        'li2014': [],\n",
    "        'behar2013': [],\n",
    "        'average_qrs': [],\n",
    "        'geometric': [],\n",
    "        'all': [],\n",
    "        'y_list': []\n",
    "    }\n",
    "\n",
    "    ## Calculate multi-lead features\n",
    "    ## Remove baseline wader and dc offset with highpass Butterworth. Also remove powerline interference (50hz).        \n",
    "    ecg_cleaned_list = [\n",
    "        nk.ecg_clean(subject_dict[channel]['data'], sampling_rate=sampling_rate, method=\"neurokit\")\n",
    "        for channel in subject_dict.keys()\n",
    "        ]\n",
    "\n",
    "    i_sqi = sqis.i_sqi(ecg_cleaned_list, sampling_rate)\n",
    "    pca_sqi = sqis.pca_sqi(np.array(ecg_cleaned_list).T) # 12 features\n",
    "    i_sqi = 0\n",
    "    pca_sqi = 0\n",
    "\n",
    "    ## Calculate single-lead features\n",
    "    for i, channel in enumerate(subject_dict.keys()):\n",
    "        ecg_raw = subject_dict[channel]['data']\n",
    "        ecg_cleaned = ecg_cleaned_list[i]\n",
    "        X_features_dict['y_list'].append(subject_dict[channel]['label'])\n",
    "\n",
    "        ## Find peaks indices\n",
    "        peaks = nk.ecg_peaks(ecg_cleaned, sampling_rate=sampling_rate, method='kalidas2017')[1]['ECG_R_Peaks']\n",
    "\n",
    "        ## Featurize ecgs\n",
    "        ecg_features = featurization.featurize_ecg(window=ecg_cleaned, sampling_rate=sampling_rate)\n",
    "        \n",
    "        ## Obtain ECG sqis for single channel\n",
    "        orphanidou2015_sqi = sqis.orphanidou2015_sqi(ecg_cleaned, sampling_rate, show=False)\n",
    "        averageQRS_sqi = sqis.averageQRS_sqi(ecg_cleaned, sampling_rate)\n",
    "        zhao2018_sqi = sqis.zhao2018_sqi(ecg_cleaned, sampling_rate)\n",
    "        p_sqi = sqis.p_sqi(ecg_cleaned, sampling_rate, window=window_size, num_spectrum=[5, 15], dem_spectrum=[5, 40])\n",
    "        bas_sqi = sqis.bas_sqi(ecg_cleaned, sampling_rate, window=window_size, num_spectrum=[0, 1], dem_spectrum=[0, 40])\n",
    "        c_sqi = sqis.c_sqi(ecg_cleaned, sampling_rate)\n",
    "        q_sqi = sqis.q_sqi(ecg_cleaned, sampling_rate, matching_qrs_frames_tolerance=50)\n",
    "        b_sqi = sqis.q_sqi(ecg_cleaned, sampling_rate, method='b_sqi')\n",
    "        bs_sqi = sqis.bs_sqi(ecg_cleaned, peaks, sampling_rate)\n",
    "        e_sqi = sqis.e_sqi(ecg_cleaned, peaks, sampling_rate)\n",
    "        hf_sqi = sqis.hf_sqi(ecg_raw, peaks, sampling_rate)\n",
    "        rsd_sqi = sqis.rsd_sqi(ecg_cleaned, peaks, sampling_rate)\n",
    "        k_sqi = sqis.k_sqi(ecg_cleaned, kurtosis_method='fisher')\n",
    "        s_sqi = sqis.s_sqi(ecg_cleaned)\n",
    "        pur_sqi = sqis.pur_sqi(ecg_cleaned)\n",
    "        ent_sqi = sqis.ent_sqi(ecg_cleaned)\n",
    "        zc_sqi = sqis.zc_sqi(ecg_cleaned)\n",
    "        f_sqi = sqis.f_sqi(ecg_cleaned, window_size=3, threshold=1e-7)\n",
    "\n",
    "        X_features_dict['zhao2018'].append([zhao2018_sqi])\n",
    "        X_features_dict['orphanidou2015'].append([orphanidou2015_sqi])\n",
    "        X_features_dict['li2007'].append([i_sqi, b_sqi, p_sqi, k_sqi])\n",
    "        X_features_dict['clifford2012'].append([i_sqi, b_sqi, p_sqi, k_sqi, s_sqi, f_sqi, bas_sqi])\n",
    "        X_features_dict['li2014'].append([i_sqi, b_sqi, p_sqi, k_sqi, s_sqi, f_sqi, bas_sqi, bs_sqi, e_sqi, hf_sqi, pur_sqi, rsd_sqi, ent_sqi])\n",
    "        X_features_dict['behar2013'].append([k_sqi, s_sqi, p_sqi, b_sqi, i_sqi, pca_sqi])\n",
    "        X_features_dict['average_qrs'].append([averageQRS_sqi])\n",
    "        X_features_dict['geometric'].append(ecg_features)\n",
    "        X_features_dict['all'].append(ecg_features + [i_sqi, pca_sqi, p_sqi, bas_sqi, c_sqi, b_sqi, q_sqi, bs_sqi, e_sqi, hf_sqi, rsd_sqi, k_sqi, s_sqi, \\\n",
    "            pur_sqi, ent_sqi, zc_sqi, f_sqi, np.nanmean(ecg_cleaned), np.nanstd(ecg_cleaned), np.nanmax(ecg_cleaned), np.nanmin(ecg_cleaned)])\n",
    "\n",
    "    return X_features_dict\n",
    "\n",
    "output_dict = datasets.load_picc(data_path=data_path, verbose=False)\n",
    "\n",
    "X_features_dict = {'zhao2018': [], 'orphanidou2015': [], 'li2007': [], 'clifford2012': [],\n",
    "    'li2014': [], 'behar2013': [], 'average_qrs': [], 'geometric': [],\n",
    "    'all': [], 'y_list': [], 'subject': []}\n",
    "\n",
    "with multiprocessing.Pool(processes=10) as pool:\n",
    "    X_features_dicts = list(tqdm(pool.imap(get_features, [output_dict[subject] for subject in output_dict.keys()]), total=len(output_dict.keys())))\n",
    "    for i, d in enumerate(X_features_dicts):\n",
    "        for key in d.keys():\n",
    "            X_features_dict[key].extend(d[key])\n",
    "        \n",
    "        X_features_dict['subject'].extend([i for _ in range(len(d['y_list']))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that exact results cannot be reproduced as the official PICC challenge is trained on the entirety of set-a and evaluated on set-b\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "\n",
    "subjects = np.array(X_features_dict['subject'])\n",
    "gkf = sklearn.model_selection.GroupKFold(n_splits=5)\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "\n",
    "print('Method, AUC, Accuracy')\n",
    "# for method in list(X_features_dict.keys()):\n",
    "for method in ['li2007', 'clifford2012', 'behar2013', 'li2014', 'orphanidou2015', 'average_qrs', 'zhao2018', 'geometric', 'all']:\n",
    "    if method == 'y_list': continue # This is just the labels, skip as it is not a method\n",
    "    if method == 'subject': continue # This is just the subject labels, skip as it is not a method\n",
    "\n",
    "    accs = []\n",
    "    tprs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    aucs = []\n",
    "\n",
    "    for train_split, test_split in gkf.split(subjects, groups=subjects):\n",
    "        # print(\"%s %s\" % (subjects[train_split], subjects[test_split]))\n",
    "\n",
    "        X_train_features_cleaned = np.nan_to_num(np.array(X_features_dict[method])[train_split], nan=0.0, posinf=10000, neginf=-10000)\n",
    "        X_test_features_cleaned = np.nan_to_num(np.array(X_features_dict[method])[test_split], nan=0.0, posinf=10000, neginf=-10000)\n",
    "        y_train = np.array(X_features_dict['y_list'])[train_split]\n",
    "        y_test = np.array(X_features_dict['y_list'])[test_split]\n",
    "    \n",
    "        model = sklearn.ensemble.RandomForestClassifier(random_state=0, n_estimators=1000, max_depth=5, n_jobs=10)\n",
    "        # model = sklearn.svm.SVC(random_state=0, probability=True)\n",
    "        print(method, 'X_train shape', X_train_features_cleaned.shape, 'X_test shape', X_test_features_cleaned.shape)\n",
    "        model.fit(X_train_features_cleaned, y_train)\n",
    "\n",
    "        scores = model.predict_proba(X_test_features_cleaned)[:,1]\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, scores, pos_label=1)\n",
    "        accs.append(model.score(X_test_features_cleaned, y_test))\n",
    "        aucs.append(sklearn.metrics.auc(fpr, tpr))\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=method)\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.grid(); plt.legend(loc=\"lower right\")\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color=\"navy\", linestyle=\"--\")\n",
    "    plt.xscale('log'); \n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=method)\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.grid(); plt.legend(loc=\"lower right\")\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color=\"navy\", linestyle=\"--\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(1-mean_tpr, 1-mean_fpr, label=method)\n",
    "    plt.xlabel('FNR'); plt.ylabel('TNR'); plt.grid(); plt.legend(loc=\"upper left\")\n",
    "    plt.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), color=\"navy\", linestyle=\"--\")\n",
    "    plt.xscale('log')\n",
    "#     plt.plot(mean_fpr, mean_tpr, label=method+r\", auc={:0.3f}$\\pm${:0.3f}\".format(np.mean(aucs), np.std(aucs)))\n",
    "    # plt.fill_between(mean_fpr, mean_tpr-std_tpr, mean_tpr+std_tpr, alpha=.2)\n",
    "    print(\"{}, {:0.3f} $\\pm$ {:0.3f}, {:0.3f} $\\pm$ {:0.3f}\".format(method, np.mean(aucs), np.std(aucs), np.mean(accs), np.std(accs)))\n",
    "\n",
    "plt.savefig('sqi_single_lead_feats.pdf', formatstr='pdf')\n",
    "plt.show()\n",
    "# plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.0]); \n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\"); plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\"); plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03fdc303e447c85257badfce409906c7c1c4ada5d52025cf8661518429577854"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
